{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd41bf-5ee6-4d82-8929-b11577963467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import cudaq\n",
    "from cudaq import spin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c2a32-a469-488b-8610-1b6d66ca65bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize((32, 32))])\n",
    "batch_size = 1\n",
    "sample_count = 1000\n",
    "\n",
    "X_train = datasets.SVHN(root=\"./data\", split='train', download=True, transform=transform)\n",
    "idx = np.append(\n",
    "    np.where(X_train.labels == 0)[0][:sample_count],\n",
    "    np.where(X_train.labels == 1)[0][:sample_count],\n",
    ")\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.labels = X_train.labels[idx]\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97e280-927b-465c-8c20-152252326f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_count = 200\n",
    "\n",
    "X_test = datasets.SVHN(root=\"./data\", split='test', download=True, transform=transform)\n",
    "idx = np.append(\n",
    "    np.where(X_test.labels == 0)[0][:sample_count],\n",
    "    np.where(X_test.labels == 1)[0][:sample_count],\n",
    ")\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.labels = X_test.labels[idx]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(X_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48027278-4522-49e3-82a8-e02ec4c8bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    # img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "print(labels)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1c8aa7-7e26-4ad7-853a-cf3be474b6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumCircuit:\n",
    "    \"\"\"This class defines the quantum circuit structure and the run method which is used to calculate an expectation value\"\"\"\n",
    "\n",
    "    def __init__(self, qubit_count: int):\n",
    "        \"\"\"Define the quantum circuit in CUDA Quantum\"\"\"\n",
    "\n",
    "        kernel, thetas = cudaq.make_kernel(list)\n",
    "\n",
    "        self.kernel = kernel\n",
    "\n",
    "        self.theta = thetas\n",
    "\n",
    "        qubits = kernel.qalloc(qubit_count)\n",
    "\n",
    "        self.kernel.h(qubits)\n",
    "\n",
    "        # Variational gate parameters which are optimised during training\n",
    "        for i in range(qubit_count):\n",
    "            kernel.rx(thetas[4*i], qubits[i])\n",
    "            if i != qubit_count - 1:\n",
    "                kernel.crx(thetas[4*i + 1], qubits[i], qubits[i+1])\n",
    "            else:\n",
    "                kernel.crx(thetas[4*i + 1], qubits[i], qubits[0])\n",
    "            \n",
    "            kernel.ry(thetas[4*i + 2], qubits[i])\n",
    "            if i != qubit_count - 1:\n",
    "                kernel.cry(thetas[4*i + 3], qubits[i], qubits[i+1])\n",
    "            else:\n",
    "                kernel.cry(thetas[4*i + 3], qubits[i], qubits[0])\n",
    "\n",
    "        hamiltonian = spin.z(0)\n",
    "        for i in range(1, qubit_count):\n",
    "            hamiltonian *= spin.z(i)\n",
    "        # print(hamiltonian)\n",
    "        self.hamiltonian = hamiltonian\n",
    "\n",
    "    def run(self, thetas: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"Excetute the quantum circuit to output an expectation value\"\"\"\n",
    "        expectation = torch.tensor(cudaq.observe(self.kernel, self.hamiltonian,\n",
    "                                                 thetas).expectation(),\n",
    "                                   device=device)\n",
    "\n",
    "        return expectation\n",
    "class QuantumFunction(Function):\n",
    "    \"\"\"Allows the quantum circuit to pass data through it and compute the gradients\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, thetas: torch.tensor, quantum_circuit,\n",
    "                shift) -> torch.tensor:\n",
    "        # Save shift and quantum_circuit in context to use in backward\n",
    "        ctx.shift = shift\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "\n",
    "        # Calculate exp_val\n",
    "        expectation_z = ctx.quantum_circuit.run(thetas)\n",
    "\n",
    "        ctx.save_for_backward(thetas, expectation_z)\n",
    "        #print(expectation_z)\n",
    "        return expectation_z\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"Backward pass computation via finite difference parameter shift\"\"\"\n",
    "\n",
    "        thetas, expectation_z = ctx.saved_tensors\n",
    "\n",
    "        gradients = torch.zeros(len(thetas), device=device)\n",
    "\n",
    "        for i in range(len(thetas)):\n",
    "            shift_right = torch.clone(thetas)\n",
    "\n",
    "            shift_right[i] += ctx.shift\n",
    "\n",
    "            shift_left = torch.clone(thetas)\n",
    "\n",
    "            shift_left[i] -= ctx.shift\n",
    "\n",
    "            expectation_right = ctx.quantum_circuit.run(shift_right)\n",
    "            expectation_left = ctx.quantum_circuit.run(shift_left)\n",
    "\n",
    "            gradients[i] = 0.5 * (expectation_right - expectation_left)\n",
    "\n",
    "        return gradients * grad_output.float(), None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598a317e-a5d5-4167-bb9a-4cbd2a12da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumLayer(nn.Module):\n",
    "    \"\"\"Encapsulates a quantum circuit and a quantum function into a quantum layer\"\"\"\n",
    "\n",
    "    def __init__(self, shift: torch.tensor):\n",
    "        super(QuantumLayer, self).__init__()\n",
    "        self.quantum_circuit = QuantumCircuit(4)\n",
    "        self.shift = shift\n",
    "\n",
    "    def forward(self, input):\n",
    "        ans = QuantumFunction.apply(input, self.quantum_circuit, self.shift)\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9785df35-39a7-4e42-8311-48234e4b9f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 16)\n",
    "        self.hybrid = QuantumLayer(\n",
    "            torch.tensor(np.pi / 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x)).reshape(-1)\n",
    "        # print(x)\n",
    "        x = F.softmax(x).reshape(-1)\n",
    "        print(x)\n",
    "        D = x.max() - x.min()\n",
    "        x = x // (D/8)\n",
    "        print(x)\n",
    "        x = self.hybrid(x).reshape(-1)\n",
    "        return torch.cat((x, 1 - x), -1).unsqueeze(0)\n",
    "\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c1a5bf-61ca-4521-8904-75e2de51cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51020d3-bf47-4ca7-ade4-566a8681f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_time = time.time()\n",
    "for epoch in range(9):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 400 == 399:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 400:.3f}')\n",
    "            running_loss = 0.0\n",
    "ed_time = time.time()\n",
    "print('Finished Training')\n",
    "print('time taken: ', ed_time - st_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb205e-6e2a-43ec-a9fb-882501c66493",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finished Training')\n",
    "ed_time = time.time()\n",
    "print('time taken: ', ed_time - st_time)\n",
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
