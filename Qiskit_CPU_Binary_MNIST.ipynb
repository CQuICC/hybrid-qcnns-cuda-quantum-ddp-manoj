{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b03ad2d-4db0-4f97-a3eb-235826b16c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_aer.primitives import Estimator\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_algorithms.utils import algorithm_globals\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "import time\n",
    "from qiskit.circuit import ParameterVector\n",
    "\n",
    "# Set seed for random generators\n",
    "algorithm_globals.random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d1cd6a-c0b2-4622-92d3-93cd62522ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional torch-related imports\n",
    "import torch\n",
    "from torch import cat, no_grad, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.nn import (\n",
    "    Module,\n",
    "    Conv2d,\n",
    "    Linear,\n",
    "    Dropout2d,\n",
    "    NLLLoss,\n",
    "    MaxPool2d,\n",
    "    Flatten,\n",
    "    Sequential,\n",
    "    ReLU,\n",
    ")\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd18cada-2be6-46a5-af5f-6f713307bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Dataset\n",
    "# -------------\n",
    "\n",
    "# Set train shuffle seed (for reproducibility)\n",
    "manual_seed(42)\n",
    "\n",
    "batch_size = 1\n",
    "n_samples = 100  # We will concentrate on the first 100 samples\n",
    "\n",
    "# Use pre-defined torchvision function to load MNIST train data\n",
    "X_train = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "idx = torch.where((X_train.targets >= 0) & (X_train.targets <= 1))[0][:n_samples]\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "\n",
    "# Define torch dataloader with filtered data\n",
    "train_loader = DataLoader(X_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1c3dd-07ee-4bea-b4de-0143a6c23839",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_show = 6\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "while n_samples_show > 0:\n",
    "    images, targets = data_iter.__next__()\n",
    "\n",
    "    axes[n_samples_show - 1].imshow(images[0, 0].numpy().squeeze(), cmap=\"gray\")\n",
    "    axes[n_samples_show - 1].set_xticks([])\n",
    "    axes[n_samples_show - 1].set_yticks([])\n",
    "    axes[n_samples_show - 1].set_title(\"Labeled: {}\".format(targets[0].item()))\n",
    "\n",
    "    n_samples_show -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e082a12b-f993-432d-831a-32de8045baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Dataset\n",
    "# -------------\n",
    "\n",
    "# Set test shuffle seed (for reproducibility)\n",
    "# manual_seed(5)\n",
    "\n",
    "n_samples = 50\n",
    "\n",
    "# Use pre-defined torchvision function to load MNIST test data\n",
    "X_test = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "idx = torch.where((X_test.targets >= 0) & (X_test.targets <= 1))[0][:n_samples]\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "\n",
    "# Define torch dataloader with filtered data\n",
    "test_loader = DataLoader(X_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b7aa7-cb18-4289-b201-d0967ee44216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and create QNN\n",
    "def create_qnn(num_qubits):\n",
    "    fm = QuantumCircuit(num_qubits)\n",
    "    input_parameters = ParameterVector(\"x\", 2*num_qubits)\n",
    "    for i in range(num_qubits):\n",
    "        fm.rx(input_parameters[2*i], i)\n",
    "        fm.ry(input_parameters[2*i + 1], i)\n",
    "    ansatz = RealAmplitudes(5, reps=2)\n",
    "    qc = QuantumCircuit(5)\n",
    "    qc.compose(fm, inplace=True)\n",
    "    qc.compose(ansatz, inplace=True)\n",
    "\n",
    "    sim_gpu = AerSimulator(method=\"statevector\", device='CPU', cusvaer_enable=False)\n",
    "    estimator_gpu = Estimator()\n",
    "    estimator_gpu.set_options(backend=sim_gpu, device='CPU')\n",
    "    print(estimator_gpu.options)\n",
    "\n",
    "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        input_params=input_parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        input_gradients=True,\n",
    "    )\n",
    "    return qnn\n",
    "\n",
    "\n",
    "qnn4 = create_qnn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed554b-14b3-4314-bc57-c0fd282bd755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define torch NN module\n",
    "\n",
    "\n",
    "class Net(Module):\n",
    "    def __init__(self, qnn):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(1, 2, kernel_size=5)\n",
    "        self.conv2 = Conv2d(2, 16, kernel_size=5)\n",
    "        self.dropout = Dropout2d()\n",
    "        self.fc1 = Linear(256, 64)\n",
    "        self.fc2 = Linear(64, 10)  # 2-dimensional input to QNN\n",
    "        self.qnn = TorchConnector(qnn)  # Apply torch connector, weights chosen\n",
    "        # uniformly at random from interval [-1,1].\n",
    "        self.fc3 = Linear(1, 1)  # 1-dimensional output from QNN\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.qnn(x)  # apply QNN\n",
    "        x = self.fc3(x)\n",
    "        return cat((x, 1 - x), -1)\n",
    "\n",
    "\n",
    "model4 = Net(qnn4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de624a9f-e0e8-4502-b071-e31292638295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model, optimizer, and loss function\n",
    "optimizer = optim.Adam(model4.parameters(), lr=0.001)\n",
    "loss_func = NLLLoss()\n",
    "\n",
    "# Start training\n",
    "epochs = 20  # Set number of epochs\n",
    "loss_list = []  # Store loss history\n",
    "model4.train()  # Set model to training mode\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad(set_to_none=True)  # Initialize gradient\n",
    "        output = model4(data)  # Forward pass\n",
    "        loss = loss_func(output, target)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize weights\n",
    "        total_loss.append(loss.item())  # Store loss\n",
    "    loss_list.append(sum(total_loss) / len(total_loss))\n",
    "    print(\"Training [{:.0f}%]\\tLoss: {:.4f}\".format(100.0 * (epoch + 1) / epochs, loss_list[-1]))\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3369a768-a4e5-41c4-9029-319f3aeb1025",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Time Taken: \", end_time - start_time, \"s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02181f06-7e5b-41bc-a38b-f10d55d9115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model4.state_dict(), \"model4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86de58a-5a05-4daa-81f0-3964fc47d684",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnn5 = create_qnn(5)\n",
    "model5 = Net(qnn5)\n",
    "model5.load_state_dict(torch.load(\"model4.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c226e1-7deb-4013-a1b7-c0f7631ab35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.eval()  # set model to evaluation mode\n",
    "with no_grad():\n",
    "\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        output = model5(data)\n",
    "        if len(output.shape) == 1:\n",
    "            output = output.reshape(1, *output.shape)\n",
    "\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "    print(\n",
    "        \"Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%\".format(\n",
    "            sum(total_loss) / len(total_loss), correct / len(test_loader) / batch_size * 100\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928a8cbc-f1dd-496f-8605-3e1d7fa658aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
